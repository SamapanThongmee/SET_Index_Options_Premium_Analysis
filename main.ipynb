{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <b>Install Library</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <b>SET50 Index Futures</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'SET50_Index_Futures.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\samap\\OneDrive\\เอกสาร\\GitHub\\SET_Index_Options_Premium_Analysis\\main.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/samap/OneDrive/%E0%B9%80%E0%B8%AD%E0%B8%81%E0%B8%AA%E0%B8%B2%E0%B8%A3/GitHub/SET_Index_Options_Premium_Analysis/main.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mSET50_Index_Futures.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samap/OneDrive/%E0%B9%80%E0%B8%AD%E0%B8%81%E0%B8%AA%E0%B8%B2%E0%B8%A3/GitHub/SET_Index_Options_Premium_Analysis/main.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data \u001b[39m=\u001b[39m data[(data[\u001b[39m'\u001b[39m\u001b[39mSymbol\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mS50M06\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m&\u001b[39m (data[\u001b[39m'\u001b[39m\u001b[39mSymbol\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mS50H07\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m&\u001b[39m (data[\u001b[39m'\u001b[39m\u001b[39mSymbol\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mS50M07\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m&\u001b[39m (data[\u001b[39m'\u001b[39m\u001b[39mSymbol\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mS50U07\u001b[39m\u001b[39m'\u001b[39m)]\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samap/OneDrive/%E0%B9%80%E0%B8%AD%E0%B8%81%E0%B8%AA%E0%B8%B2%E0%B8%A3/GitHub/SET_Index_Options_Premium_Analysis/main.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mpivot(index\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m, columns\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSymbol\u001b[39m\u001b[39m'\u001b[39m, values\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSP\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreset_index()\u001b[39m.\u001b[39mdrop_duplicates(subset\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m, keep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlast\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\samap\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\samap\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\samap\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_engine(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\samap\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmemory_map\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding_errors\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mstorage_options\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\samap\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'SET50_Index_Futures.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('SET50_Index_Futures.csv')\n",
    "data = data[(data['Symbol'] != 'S50M06') & (data['Symbol'] != 'S50H07') & (data['Symbol'] != 'S50M07') & (data['Symbol'] != 'S50U07')].reset_index(drop=True)\n",
    "data = data.pivot(index='Date', columns='Symbol', values='SP').reset_index().drop_duplicates(subset='Date', keep='last')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data = data[data['Date'] >= '2007-10-29'].reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <b>Manipulate SET50 Index Futures</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_nearest_25(value):\n",
    "    return 25 * round(value / 25)\n",
    "\n",
    "def round_to_nearest_50(value):\n",
    "    return 50 * round(value / 50)\n",
    "\n",
    "def vlookup_call(row, file_prefix):\n",
    "    strike_price = row['Strike Price']\n",
    "    column_name = f'{file_prefix}C{strike_price}'\n",
    "    atm_value = row[column_name]\n",
    "\n",
    "    return atm_value\n",
    "\n",
    "def vlookup_put(row, file_prefix):\n",
    "    strike_price = row['Strike Price']\n",
    "    column_name = f'{file_prefix}P{strike_price}'\n",
    "    atm_value = row[column_name]\n",
    "\n",
    "    return atm_value\n",
    "\n",
    "column_names_25 = ['S50H14', 'S50H15', 'S50H16', 'S50H17', 'S50H18', 'S50H19', 'S50H20', 'S50H21', 'S50H22', 'S50H23', \n",
    "                   'S50M14', 'S50M15', 'S50M16', 'S50M17', 'S50M18', 'S50M19', 'S50M20', 'S50M21', 'S50M22', 'S50M23', \n",
    "                   'S50U13', 'S50U14', 'S50U15', 'S50U16', 'S50U17', 'S50U18', 'S50U19', 'S50U20', 'S50U21', 'S50U22', 'S50U23', \n",
    "                   'S50Z13', 'S50Z14', 'S50Z15', 'S50Z16', 'S50Z17', 'S50Z18', 'S50Z19', 'S50Z20', 'S50Z21', 'S50Z22', 'S50Z23']\n",
    "    \n",
    "column_names_50 = ['S50H08', 'S50H09', 'S50H10', 'S50H11', 'S50H12', 'S50H13',\n",
    "                   'S50M08', 'S50M09', 'S50M10', 'S50M11', 'S50M12', 'S50M13',\n",
    "                   'S50U06', 'S50U08', 'S50U09', 'S50U10', 'S50U11', 'S50U12',\n",
    "                   'S50Z06', 'S50Z07', 'S50Z08', 'S50Z09', 'S50Z10', 'S50Z11', 'S50Z12']\n",
    "\n",
    "# Dictionary to store DataFrames\n",
    "dfs_25 = {}\n",
    "dfs_50 = {}\n",
    "\n",
    "# Create DataFrames for 'column_names_25'\n",
    "for column in column_names_25:\n",
    "    selected_columns = ['Date', column]\n",
    "    new_df_25 = data[selected_columns].dropna().reset_index(drop=True)\n",
    "    \n",
    "    # Calculate Strike_Price column with the round_to_nearest_25 function\n",
    "    new_df_25['Strike Price'] = new_df_25[column].apply(round_to_nearest_25)\n",
    "    \n",
    "    # Store the DataFrame in the dictionary\n",
    "    dfs_25[column] = new_df_25\n",
    "\n",
    "# Create DataFrames for 'column_names_50'\n",
    "for column in column_names_50:\n",
    "    selected_columns = ['Date', column]\n",
    "    new_df_50 = data[selected_columns].dropna().reset_index(drop=True)\n",
    "    \n",
    "    # Calculate Strike_Price column with the round_to_nearest_50 function\n",
    "    new_df_50['Strike Price'] = new_df_50[column].apply(round_to_nearest_50)\n",
    "    \n",
    "    # Store the DataFrame in the dictionary\n",
    "    dfs_50[column] = new_df_50\n",
    "\n",
    "# Interval 25\n",
    "S50H14 = dfs_25['S50H14']; S50H15 = dfs_25['S50H15']; S50H16 = dfs_25['S50H16']; S50H17 = dfs_25['S50H17']\n",
    "S50H18 = dfs_25['S50H18']; S50H19 = dfs_25['S50H19']; S50H20 = dfs_25['S50H20']; S50H21 = dfs_25['S50H21']\n",
    "S50H22 = dfs_25['S50H22']; S50H23 = dfs_25['S50H23']\n",
    "\n",
    "S50M14 = dfs_25['S50M14']; S50M15 = dfs_25['S50M15']; S50M16 = dfs_25['S50M16']; S50M17 = dfs_25['S50M17']\n",
    "S50M18 = dfs_25['S50M18']; S50M19 = dfs_25['S50M19']; S50M20 = dfs_25['S50M20']; S50M21 = dfs_25['S50M21']\n",
    "S50M22 = dfs_25['S50M22']; S50M23 = dfs_25['S50M23']\n",
    "\n",
    "S50U13 = dfs_25['S50U13']; S50U14 = dfs_25['S50U14']; S50U15 = dfs_25['S50U15']; S50U16 = dfs_25['S50U16']\n",
    "S50U17 = dfs_25['S50U17']; S50U18 = dfs_25['S50U18']; S50U19 = dfs_25['S50U19']; S50U20 = dfs_25['S50U20']\n",
    "S50U21 = dfs_25['S50U21']; S50U22 = dfs_25['S50U22']; S50U23 = dfs_25['S50U23']\n",
    "\n",
    "S50Z13 = dfs_25['S50Z13']; S50Z14 = dfs_25['S50Z14']; S50Z15 = dfs_25['S50Z15']; S50Z16 = dfs_25['S50Z16']\n",
    "S50Z17 = dfs_25['S50Z17']; S50Z18 = dfs_25['S50Z18']; S50Z19 = dfs_25['S50Z19']; S50Z20 = dfs_25['S50Z20']\n",
    "S50Z21 = dfs_25['S50Z21']; S50Z22 = dfs_25['S50Z22']; S50Z23 = dfs_25['S50Z23']\n",
    "\n",
    "# Interval 50\n",
    "S50H08 = dfs_50['S50H08']; S50H09 = dfs_50['S50H09']; S50H10 = dfs_50['S50H10']; S50H11 = dfs_50['S50H11']\n",
    "S50H12 = dfs_50['S50H12']; S50H13 = dfs_50['S50H13']\n",
    "\n",
    "S50M08 = dfs_50['S50M08']; S50M09 = dfs_50['S50M09']; S50M10 = dfs_50['S50M10']; S50M11 = dfs_50['S50M11']\n",
    "S50M12 = dfs_50['S50M12']; S50M13 = dfs_50['S50M13']\n",
    "\n",
    "S50U08 = dfs_50['S50U08']; S50U09 = dfs_50['S50U09']; S50U10 = dfs_50['S50U10']; S50U11 = dfs_50['S50U11']\n",
    "S50U12 = dfs_50['S50U12']\n",
    "\n",
    "S50Z07 = dfs_50['S50Z07']; S50Z08 = dfs_50['S50Z08']; S50Z09 = dfs_50['S50Z09']; S50Z10 = dfs_50['S50Z10']\n",
    "S50Z11 = dfs_50['S50Z11']; S50Z12 = dfs_50['S50Z12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <b>Combined SET50 Index Futures and SET50 Index Options</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <b>Create Functions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_options_data(futures_symbol):\n",
    "    Call_Options_data = pd.read_csv(f'{futures_symbol}_Call_options_data.csv')\n",
    "    Call_Options = Call_Options_data[['Date', 'Symbol', 'SP']]\n",
    "    Call_Options = Call_Options.sort_values(by='Date').reset_index(drop=True)\n",
    "\n",
    "    Put_Options_data = pd.read_csv(f'{futures_symbol}_Put_options_data.csv')\n",
    "    Put_Options = Put_Options_data[['Date', 'Symbol', 'SP']]\n",
    "    Put_Options = Put_Options.sort_values(by='Date').reset_index(drop=True)\n",
    "\n",
    "    # Select options first day trade\n",
    "    first_day = Call_Options['Date'].min()\n",
    "    Futures['Date'] = pd.to_datetime(Futures['Date'])\n",
    "    mask = Futures['Date'] >= pd.to_datetime(first_day)\n",
    "    Futures_subset = Futures[mask].reset_index(drop=True)\n",
    "    Futures_subset['Date'] = pd.to_datetime(Futures_subset['Date'])\n",
    "    Futures_subset = Futures_subset.sort_values(by='Date').reset_index(drop=True)\n",
    "\n",
    "    call_options_unique_symbols = Call_Options['Symbol'].unique()\n",
    "    symbol_dataframes = {}\n",
    "\n",
    "    for symbol in call_options_unique_symbols:\n",
    "        symbol_df = pd.DataFrame({\n",
    "            'Date': Call_Options[Call_Options['Symbol'] == symbol]['Date'],\n",
    "            symbol: Call_Options[Call_Options['Symbol'] == symbol]['SP']\n",
    "        })\n",
    "        symbol_dataframes[symbol] = symbol_df\n",
    "\n",
    "    merged_df = symbol_dataframes[call_options_unique_symbols[0]]\n",
    "    for symbol in call_options_unique_symbols[1:]:\n",
    "        merged_df = pd.merge(merged_df, symbol_dataframes[symbol], on='Date', how='outer')\n",
    "\n",
    "    Call_Options_Clean = merged_df.drop_duplicates(subset=['Date']).sort_values(by='Date').reset_index(drop=True).fillna(0)\n",
    "    Call_Options_Clean['Date'] = pd.to_datetime(Call_Options_Clean['Date'])\n",
    "\n",
    "    put_options_unique_symbols = Put_Options['Symbol'].unique()\n",
    "    symbol_dataframes = {}\n",
    "\n",
    "    for symbol in put_options_unique_symbols:\n",
    "        symbol_df = pd.DataFrame({\n",
    "            'Date': Put_Options[Put_Options['Symbol'] == symbol]['Date'],\n",
    "            symbol: Put_Options[Put_Options['Symbol'] == symbol]['SP']\n",
    "        })\n",
    "        symbol_dataframes[symbol] = symbol_df\n",
    "\n",
    "    merged_df = symbol_dataframes[put_options_unique_symbols[0]]\n",
    "    for symbol in put_options_unique_symbols[1:]:\n",
    "        merged_df = pd.merge(merged_df, symbol_dataframes[symbol], on='Date', how='outer')\n",
    "\n",
    "    Put_Options_Clean = merged_df.drop_duplicates(subset=['Date']).sort_values(by='Date').reset_index(drop=True).fillna(0)\n",
    "    Put_Options_Clean['Date'] = pd.to_datetime(Put_Options_Clean['Date'])\n",
    "\n",
    "    Data = Futures_subset.merge(Call_Options_Clean, on='Date', how='outer').fillna(0)\n",
    "    Data = Data.merge(Put_Options_Clean, on='Date', how='outer').fillna(0)\n",
    "    Data['Date'] = pd.to_datetime(Data['Date'])\n",
    "    Data = Data.sort_values(by='Date').reset_index(drop=True)\n",
    "    Data['Strike Price'] = Data['Strike Price'].astype(int)\n",
    "    Data['Call ATM'] = Data.apply(vlookup_call, axis=1, args=(futures_symbol,))\n",
    "    Data['Put ATM'] = Data.apply(vlookup_put, axis=1, args=(futures_symbol,))\n",
    "    Data = Data[['Date', 'Strike Price', 'Call ATM', 'Put ATM']]\n",
    "    Data['Sum Premium'] = (Data['Call ATM'] + Data['Put ATM'])\n",
    "    Data['Normalized Premium'] = Data['Strike Price'] / Data['Sum Premium']\n",
    "\n",
    "    return Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <b>S50U13 to S50Z23</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2013\n",
    "Futures = S50U13\n",
    "Futures_symbol = 'S50U13'\n",
    "S50U13 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50Z13\n",
    "Futures_symbol = 'S50Z13'\n",
    "S50Z13 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "# Options_2013 = pd.concat([S50H13, S50M13, S50U13, S50Z13], axis=1)\n",
    "Options_2013 = pd.concat([S50U13, S50Z13], axis=1)\n",
    "Options_2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2014\n",
    "Futures = S50H14\n",
    "Futures_symbol = 'S50H14'\n",
    "S50H14 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50M14\n",
    "Futures_symbol = 'S50M14'\n",
    "S50M14 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50U14\n",
    "Futures_symbol = 'S50U14'\n",
    "S50U14 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50Z14\n",
    "Futures_symbol = 'S50Z14'\n",
    "S50Z14 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Options_2014 = pd.concat([S50H14, S50M14, S50U14, S50Z14], axis=1)\n",
    "Options_2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2015\n",
    "Futures = S50H15\n",
    "Futures_symbol = 'S50H15'\n",
    "S50H15 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50M15\n",
    "Futures_symbol = 'S50M15'\n",
    "S50M15 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50U15\n",
    "Futures_symbol = 'S50U15'\n",
    "S50U15 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50Z15\n",
    "Futures_symbol = 'S50Z15'\n",
    "S50Z15 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Options_2015 = pd.concat([S50H15, S50M15, S50U15, S50Z15], axis=1)\n",
    "Options_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016\n",
    "Futures = S50H16\n",
    "Futures_symbol = 'S50H16'\n",
    "S50H16 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50M16\n",
    "Futures_symbol = 'S50M16'\n",
    "S50M16 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50U16\n",
    "Futures_symbol = 'S50U16'\n",
    "S50U16 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50Z16\n",
    "Futures_symbol = 'S50Z16'\n",
    "S50Z16 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Options_2016 = pd.concat([S50H16, S50M16, S50U16, S50Z16], axis=1)\n",
    "Options_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2017\n",
    "Futures = S50H17\n",
    "Futures_symbol = 'S50H17'\n",
    "S50H17 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50M17\n",
    "Futures_symbol = 'S50M17'\n",
    "S50M17 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50U17\n",
    "Futures_symbol = 'S50U17'\n",
    "S50U17 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50Z17\n",
    "Futures_symbol = 'S50Z17'\n",
    "S50Z17 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Options_2017 = pd.concat([S50H17, S50M17, S50U17, S50Z17], axis=1)\n",
    "Options_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018\n",
    "Futures = S50H18\n",
    "Futures_symbol = 'S50H18'\n",
    "S50H18 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50M18\n",
    "Futures_symbol = 'S50M18'\n",
    "S50M18 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50U18\n",
    "Futures_symbol = 'S50U18'\n",
    "S50U18 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50Z18\n",
    "Futures_symbol = 'S50Z18'\n",
    "S50Z18 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Options_2018 = pd.concat([S50H18, S50M18, S50U18, S50Z18], axis=1)\n",
    "Options_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019\n",
    "Futures = S50H19\n",
    "Futures_symbol = 'S50H19'\n",
    "S50H19 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50M19\n",
    "Futures_symbol = 'S50M19'\n",
    "S50M19 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50U19\n",
    "Futures_symbol = 'S50U19'\n",
    "S50U19 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50Z19\n",
    "Futures_symbol = 'S50Z19'\n",
    "S50Z19 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Options_2019 = pd.concat([S50H19, S50M19, S50U19, S50Z19], axis=1)\n",
    "Options_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020\n",
    "Futures = S50H20\n",
    "Futures_symbol = 'S50H20'\n",
    "S50H20 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50M20\n",
    "Futures_symbol = 'S50M20'\n",
    "S50M20 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50U20\n",
    "Futures_symbol = 'S50U20'\n",
    "S50U20 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50Z20\n",
    "Futures_symbol = 'S50Z20'\n",
    "S50Z20 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Options_2020 = pd.concat([S50H20, S50M20, S50U20, S50Z20], axis=1)\n",
    "Options_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2021\n",
    "Futures = S50H21\n",
    "Futures_symbol = 'S50H21'\n",
    "S50H21 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50M21\n",
    "Futures_symbol = 'S50M21'\n",
    "S50M21 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50U21\n",
    "Futures_symbol = 'S50U21'\n",
    "S50U21 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50Z21\n",
    "Futures_symbol = 'S50Z21'\n",
    "S50Z21 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Options_2021 = pd.concat([S50H21, S50M21, S50U21, S50Z21], axis=1)\n",
    "Options_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022\n",
    "Futures = S50H22\n",
    "Futures_symbol = 'S50H22'\n",
    "S50H22 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50M22\n",
    "Futures_symbol = 'S50M22'\n",
    "S50M22 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50U22\n",
    "Futures_symbol = 'S50U22'\n",
    "S50U22 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50Z22\n",
    "Futures_symbol = 'S50Z22'\n",
    "S50Z22 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Options_2022 = pd.concat([S50H22, S50M22, S50U22, S50Z22], axis=1)\n",
    "Options_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023\n",
    "Futures = S50H23\n",
    "Futures_symbol = 'S50H23'\n",
    "S50H23 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50M23\n",
    "Futures_symbol = 'S50M23'\n",
    "S50M23 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50U23\n",
    "Futures_symbol = 'S50U23'\n",
    "S50U23 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Futures = S50Z23\n",
    "Futures_symbol = 'S50Z23'\n",
    "S50Z23 = process_options_data(Futures_symbol)[['Normalized Premium']].rename(columns={'Normalized Premium': Futures_symbol})\n",
    "\n",
    "Options_2023 = pd.concat([S50H23, S50M23, S50U23, S50Z23], axis=1)\n",
    "Options_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined\n",
    "Normalized_Premium = pd.concat([Options_2013, Options_2014, Options_2015,\n",
    "                                Options_2016, Options_2017, Options_2018, Options_2019, \n",
    "                                Options_2020, Options_2021, Options_2022, Options_2023], \n",
    "                               axis=1)\n",
    "Normalized_Premium"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
